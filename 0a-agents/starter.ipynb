{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "506fab2a-a50c-42bd-a106-c83a9d2828ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-08 13:45:34--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4273 (4.2K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   4.17K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-08-08 13:45:34 (32.2 MB/s) - ‘minsearch.py’ saved [4273/4273]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -f minsearch.py\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac947de-effd-4b61-8792-a6d7a133f347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/llm-zoomcamp/0a-agents/minsearch.py:10: UserWarning: Now minsearch is installable via pip: 'pip install minsearch'. Remove the downloaded file and re-install it with pip.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x70b2f9bed190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import minsearch\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f087272-b44d-4738-9ea2-175ec63a058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "742ab881-499a-4675-83c4-2013ea1377b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='deepseek-r1',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8bff3e-b672-42be-866b-f2d9bb217106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "988ece59-951a-4b32-ba3f-cb8efb66a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local LLM\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f522f3d5-c229-4020-8ca1-64c86383c3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user wrote \"write that this is a test\" which seems like they\\'re explicitly asking me to label something as a test. \\n\\nHmm, making sure I understand what they want here - it\\'s literally asking for confirmation that whatever interaction we\\'re having is just a simulation or practice scenario. There might be some meta-awareness at play where the user wants to acknowledge our artificial nature upfront.\\n\\nThe phrasing is minimal but precise. They didn\\'t say \"I know this is AI\" or anything similar, but they did choose language that points toward testing. Maybe they\\'re checking how I handle self-references in a professional context? \\n\\nSince they\\'ve given me no additional text or scenario to work with beyond the base prompt itself, keeping it straightforward makes sense. No need to overcomplicate - just deliver exactly what was requested while maintaining appropriate formality based on their language style.\\n\\nThe user seems technically savvy enough to craft phrased intended as test verbiage properly. Might be another prompt creator themselves. But I\\'ll treat this purely transactionally unless they indicate otherwise.\\n</think>\\nThis is a test.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('write that this is a test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60d763cb-73ff-47da-bd38-4d77f418fc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wrote \"write that this is a test\" which seems like they're explicitly asking me to label something as a test. \n",
      "\n",
      "Hmm, making sure I understand what they want here - it's literally asking for confirmation that whatever interaction we're having is just a simulation or practice scenario. There might be some meta-awareness at play where the user wants to acknowledge our artificial nature upfront.\n",
      "\n",
      "The phrasing is minimal but precise. They didn't say \"I know this is AI\" or anything similar, but they did choose language that points toward testing. Maybe they're checking how I handle self-references in a professional context? \n",
      "\n",
      "Since they've given me no additional text or scenario to work with beyond the base prompt itself, keeping it straightforward makes sense. No need to overcomplicate - just deliver exactly what was requested while maintaining appropriate formality based on their language style.\n",
      "\n",
      "The user seems technically savvy enough to craft phrased intended as test verbiage properly. Might be another prompt creator themselves. But I'll treat this purely transactionally unless they indicate otherwise.\n",
      "</think>\n",
      "This is a test.\n"
     ]
    }
   ],
   "source": [
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752240a-f4d1-481e-aefe-d993de06cc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
