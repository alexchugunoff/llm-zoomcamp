{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f25c4f2-ebea-41c4-87ea-eb723c72222c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac620d42-ac6b-4177-a582-8b761dd3a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch\n",
    "import requests\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "from mistralai import Mistral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2c68a9-6efb-48ab-af7e-3b29af7f7ea0",
   "metadata": {},
   "source": [
    "# Part 0: Basic RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6142f9-9c81-4626-bfce-f5c6eb66a116",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff6a95cc-2aa7-49b2-8673-fc49ad3eaeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "965b738a-886a-4b6f-821c-c896d724274d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x7c46c4207860>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479fb367-2aef-404d-adef-01ab543691ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c578f9d-6302-4905-8bf2-d5cec7431c9c",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f50bd61f-b571-403a-b21f-15cb8c1aa09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f063c-98d3-4d99-8756-9760f9a9484b",
   "metadata": {},
   "source": [
    "## The RAG flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f4ba937-68da-4a8c-884b-02adf795ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "model = \"mistral-large-latest\"\n",
    "\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.complete(\n",
    "        model= model,\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651bff18-ab0a-4778-99db-2102c9168031",
   "metadata": {},
   "source": [
    "# Part 1: Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58cc2b87-33e9-4a04-abfd-eaa585c9e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making RAG more agentic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad3277e-42f3-47c4-a1ad-08e4ae67a9a9",
   "metadata": {},
   "source": [
    "## Update Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c709242-f529-4349-85a8-7b13ecd7840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "If CONTEXT is EMPTY, you can use our FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d826d0-a976-4024-b498-eb409bc56bfd",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b17feac7-c81e-4882-931b-4ff28b3b08bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "how do I run docker on gentoo?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To run Docker on Gentoo, you need to follow these general steps:\\n\\n1. **Install Docker**: You can install Docker using the Portage package manager. First, ensure your system is up-to-date:\\n```\\nsudo emerge --sync\\nsudo emerge --update --deep --newuse @world\\n```\\nThen, install Docker:\\n```\\nsudo emerge app-emulation/docker\\n```\\n2. **Start the Docker Service**: After installation, start the Docker service:\\n```\\nsudo systemctl start docker\\n```\\nTo enable Docker to start on boot, use:\\n```\\nsudo systemctl enable docker\\n```\\n3. **Run Docker Commands**: You can now run Docker commands. For example, to run a simple Docker container:\\n```\\nsudo docker run hello-world\\n```\\nThis will download a test image and run it in a container. If the setup is correct, you should see a 'Hello from Docker!' message.\\n\\n4. **Add Your User to the Docker Group** (optional but recommended):\\n```\\nsudo usermod -aG docker $USER\\n```\\nAfter adding your user to the docker group, log out and log back in so that your group membership is re-evaluated. This allows you to run Docker commands without using sudo.\\n\\nThese steps should help you get Docker up and running on Gentoo. If you encounter any issues, make sure to check the Gentoo and Docker documentation for more detailed instructions.\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I run docker on gentoo?\"\n",
    "context = \"EMPTY\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)\n",
    "\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31a02f9d-ce3d-4068-9c37-b9ab9d9e5f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"The CONTEXT is EMPTY, so I need to search the FAQ database to find the information on how to join the course.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I join the course?\"\n",
    "context = \"EMPTY\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deaff99-4b9c-4670-ab8b-2406d53176cd",
   "metadata": {},
   "source": [
    "## Implement make the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623430ca-3e25-4da1-aea1-4cd85287ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, build_context is a helper function from the previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57d0d4de-f382-4165-b724-dc93ef5490f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d1bc41b-8b95-4a54-88eb-3a285af90813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "how do I join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "search_results = search(question)\n",
    "context = build_context(search_results)\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eb0e4ce-c569-49f6-8244-0e98a24ca63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To join the course, you need to register before it starts using this link. Additionally, join the course Telegram channel for announcements and register in DataTalks.Club's Slack to join the relevant channel.\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Check once again\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92daa29d-ac83-4aee-8543-eda842a9bd83",
   "metadata": {},
   "source": [
    "## Put this together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa285312-b94b-4908-9274-0c6762f03217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First attempt to answer it with our know knowledge\n",
    "# If needed, do the lookup and then answer\n",
    "def agentic_rag_v1(question):\n",
    "    context = \"EMPTY\"\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(answer)\n",
    "\n",
    "    if answer['action'] == 'SEARCH':\n",
    "        print('need to perform search...')\n",
    "        search_results = search(question)\n",
    "        context = build_context(search_results)\n",
    "        \n",
    "        prompt = prompt_template.format(question=question, context=context)\n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121df5a-6555-4751-9133-8b3e2f462ea1",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27690b37-a377-4063-916a-e8b62c7811e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agentic_rag_v1('how do I join the course?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00027513-e48b-4b6d-971c-93c8306fe5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agentic_rag_v1('how patch KDE under FreeBSD?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e137ff66-06c0-41e6-b32f-b8d2225f738b",
   "metadata": {},
   "source": [
    "# Part 2: Agentic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c13efa-968b-4639-b4ca-c6039de93a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can let our \"agent\" formulate one or more search queries - and do it for a few iterations until we found an answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1282bf24-c4c0-48fe-b057-a52f6f19d02a",
   "metadata": {},
   "source": [
    "## Update Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374280d1-4f58-4b30-9897-e879d9f49109",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "\n",
    "The CONTEXT is build with the documents from our FAQ database.\n",
    "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
    "from FAQ to and add them to the context.\n",
    "PREVIOUS_ACTIONS contains the actions you already performed.\n",
    "\n",
    "At the beginning the CONTEXT is empty.\n",
    "\n",
    "You can perform the following actions:\n",
    "\n",
    "- Search in the FAQ database to get more data for the CONTEXT\n",
    "- Answer the question using the CONTEXT\n",
    "- Answer the question using your own knowledge\n",
    "\n",
    "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
    "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
    "\n",
    "Don't use search queries used at the previous iterations.\n",
    "\n",
    "Don't repeat previously performed actions.\n",
    "\n",
    "Don't perform more than {max_iterations} iterations for a given student question.\n",
    "The current iteration number: {iteration_number}. If we exceed the allowed number \n",
    "of iterations, give the best possible answer with the provided information.\n",
    "\n",
    "Output templates:\n",
    "\n",
    "If you want to perform search, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\",\n",
    "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER_CONTEXT\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{previous_actions}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5e69ef-f4c4-4524-b08e-ee9258ded7e7",
   "metadata": {},
   "source": [
    "## First iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12801c77-0656-4c41-a47d-e8f95e8615d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the first iteration, we have this\n",
    "question = \"how do I join the course?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=3,\n",
    "    iteration_number=1\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f6e0a-a473-4986-b587-5a95365aae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(json.dumps(answer, indent=2))\n",
    "\n",
    "# {\n",
    "#   \"action\": \"SEARCH\",\n",
    "#   \"reasoning\": \"I need to find specific information on how to join the course, as this information is not present in the current CONTEXT.\",\n",
    "#   \"keywords\": [\n",
    "#     \"how to join the course\",\n",
    "#     \"course enrollment process\",\n",
    "#     \"register for the course\"\n",
    "#   ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dcb187-dd8b-447e-815f-f9d6ee7a334b",
   "metadata": {},
   "source": [
    "## Save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a51e0-bb12-410e-a845-5cf6d949414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to save the actions\n",
    "previous_actions.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f94553-20b0-4d75-bd0d-8c71af32ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the search queries\n",
    "keywords = answer['keywords']\n",
    "search_queries.extend(keywords)\n",
    "\n",
    "# And the search results\n",
    "for k in keywords:\n",
    "    res = search(k)\n",
    "    search_results.extend(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20156e1f-4603-4e00-bfcd-1b3e9dc2b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the search results will be duplicates, so we need to remove them\n",
    "def dedup(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result\n",
    "\n",
    "search_results = dedup(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b70074-2dc7-4e92-9c4e-91d67ccf5853",
   "metadata": {},
   "source": [
    "## Another iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc71a17-0856-4bf0-93ef-9d76a66ea915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's make another iteration - use the same code as previously, \n",
    "# but remove variable initialization and increase the iteration number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e26bf-0c5c-4a50-9270-c6f6d71a364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"how do I join the course?\"\n",
    "\n",
    "# search_queries = []\n",
    "# search_results = []\n",
    "# previous_actions = []\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=3,\n",
    "    iteration_number=2\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(json.dumps(answer, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6acf70-a2f7-4ea1-b91d-51f9d1a2840f",
   "metadata": {},
   "source": [
    "## Put everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f91eaa-ebcd-441b-b429-7465c7365c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_search(question):\n",
    "    search_queries = []\n",
    "    search_results = []\n",
    "    previous_actions = []\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        print(f'ITERATION #{iteration}...')\n",
    "    \n",
    "        context = build_context(search_results)\n",
    "        prompt = prompt_template.format(\n",
    "            question=question,\n",
    "            context=context,\n",
    "            search_queries=\"\\n\".join(search_queries),\n",
    "            previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "            max_iterations=3,\n",
    "            iteration_number=iteration\n",
    "        )\n",
    "    \n",
    "        print(prompt)\n",
    "    \n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(json.dumps(answer, indent=2))\n",
    "\n",
    "        previous_actions.append(answer)\n",
    "    \n",
    "        action = answer['action']\n",
    "        if action != 'SEARCH':\n",
    "            break\n",
    "    \n",
    "        keywords = answer['keywords']\n",
    "        search_queries = list(set(search_queries) | set(keywords))\n",
    "\n",
    "        for k in keywords:\n",
    "            res = search(k)\n",
    "            search_results.extend(res)\n",
    "    \n",
    "        search_results = dedup(search_results)\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        if iteration >= 4:\n",
    "            break\n",
    "    \n",
    "        print()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5865af-5c1f-4c4f-83d3-08e9c2ffec04",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af7f83-edc2-4054-a8f5-8615a8446ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentic_search('how do I prepare for the course?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e566bb3-bce1-4ca8-81f8-a6bc550b3290",
   "metadata": {},
   "source": [
    "# Part 3: Function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f1513-abef-4a0c-9ae3-35870e801a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We put all this logic inside our prompt.\n",
    "# But OpenAI and other providers provide a convenient API for adding extra functionality like search.\n",
    "# https://platform.openai.com/docs/guides/function-calling\n",
    "# It's called \"function calling\" - you define functions that the model can call, and if it decides to make a call, it returns structured output for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c3872e-f0ca-4cdc-bfa8-6bba1477da4a",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a0843-af35-4004-80b8-1674b14cbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, let's take our search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1f58d-93f4-43e7-a3ee-fb3c2b630f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7def1a-55fe-406e-9485-843873a9da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We describe it like that\n",
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48075a5c-7d32-486a-bf02-9855b1a8a089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5816cb91-c0ec-4d32-90d6-bae1abe40987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a6063-8c52-45b2-8aed-57311d50f9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a2d97-2856-4e67-a5ec-d6ac530cb43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
