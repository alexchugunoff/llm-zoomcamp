{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f25c4f2-ebea-41c4-87ea-eb723c72222c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac620d42-ac6b-4177-a582-8b761dd3a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch\n",
    "import requests\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "from mistralai import Mistral\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2c68a9-6efb-48ab-af7e-3b29af7f7ea0",
   "metadata": {},
   "source": [
    "# Part 0: Basic RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6142f9-9c81-4626-bfce-f5c6eb66a116",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff6a95cc-2aa7-49b2-8673-fc49ad3eaeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "965b738a-886a-4b6f-821c-c896d724274d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x7825c023e480>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479fb367-2aef-404d-adef-01ab543691ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c578f9d-6302-4905-8bf2-d5cec7431c9c",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f50bd61f-b571-403a-b21f-15cb8c1aa09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f063c-98d3-4d99-8756-9760f9a9484b",
   "metadata": {},
   "source": [
    "## The RAG flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f4ba937-68da-4a8c-884b-02adf795ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "## Mistral\n",
    "# api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "# client = Mistral(api_key=api_key)\n",
    "\n",
    "# def llm(prompt):\n",
    "#     response = client.chat.complete(\n",
    "#         model= \"mistral-large-latest\",\n",
    "#         messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "#     )    \n",
    "#     return response.choices[0].message.content\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651bff18-ab0a-4778-99db-2102c9168031",
   "metadata": {},
   "source": [
    "# Part 1: Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58cc2b87-33e9-4a04-abfd-eaa585c9e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making RAG more agentic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad3277e-42f3-47c4-a1ad-08e4ae67a9a9",
   "metadata": {},
   "source": [
    "## Update Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c709242-f529-4349-85a8-7b13ecd7840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "If CONTEXT is EMPTY, you can use our FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d826d0-a976-4024-b498-eb409bc56bfd",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b17feac7-c81e-4882-931b-4ff28b3b08bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "how do I run docker on gentoo?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To run Docker on Gentoo, you need to follow these general steps:\\n\\n1. **Install Docker**: You can install Docker using the Portage package manager. First, ensure your system is up-to-date:\\n```\\nsudo emerge --sync\\nsudo emerge --update --deep --newuse @world\\n```\\nThen, install Docker:\\n```\\nsudo emerge app-emulation/docker\\n```\\n2. **Start the Docker Service**: After installation, start the Docker service:\\n```\\nsudo systemctl start docker\\n```\\nTo enable Docker to start on boot, use:\\n```\\nsudo systemctl enable docker\\n```\\n3. **Run Docker Commands**: You can now run Docker commands. For example, to run a simple Docker container:\\n```\\nsudo docker run hello-world\\n```\\nThis will download a test image and run it in a container. If the setup is correct, you should see a 'Hello from Docker!' message.\\n\\n4. **Add Your User to the Docker Group** (optional but recommended):\\n```\\nsudo usermod -aG docker $USER\\n```\\nAfter adding your user to the docker group, log out and log back in so that your group membership is re-evaluated. This allows you to run Docker commands without using sudo.\\n\\nThese steps should help you get Docker up and running on Gentoo. If you encounter any issues, make sure to check the Gentoo and Docker documentation for more detailed instructions.\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I run docker on gentoo?\"\n",
    "context = \"EMPTY\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)\n",
    "\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31a02f9d-ce3d-4068-9c37-b9ab9d9e5f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"The CONTEXT is EMPTY, so I need to search the FAQ database to find the information on how to join the course.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I join the course?\"\n",
    "context = \"EMPTY\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deaff99-4b9c-4670-ab8b-2406d53176cd",
   "metadata": {},
   "source": [
    "## Implement make the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623430ca-3e25-4da1-aea1-4cd85287ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, build_context is a helper function from the previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57d0d4de-f382-4165-b724-dc93ef5490f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d1bc41b-8b95-4a54-88eb-3a285af90813",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(question)\n",
    "context = build_context(search_results)\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eb0e4ce-c569-49f6-8244-0e98a24ca63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To join the course, you need to register before it starts using this link. Additionally, join the course Telegram channel for announcements and register in DataTalks.Club's Slack to join the relevant channel.\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Check once again\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92daa29d-ac83-4aee-8543-eda842a9bd83",
   "metadata": {},
   "source": [
    "## Put this together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa285312-b94b-4908-9274-0c6762f03217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First attempt to answer it with our know knowledge\n",
    "# If needed, do the lookup and then answer\n",
    "def agentic_rag_v1(question):\n",
    "    context = \"EMPTY\"\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(answer)\n",
    "\n",
    "    if answer['action'] == 'SEARCH':\n",
    "        print('need to perform search...')\n",
    "        search_results = search(question)\n",
    "        context = build_context(search_results)\n",
    "        \n",
    "        prompt = prompt_template.format(question=question, context=context)\n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121df5a-6555-4751-9133-8b3e2f462ea1",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27690b37-a377-4063-916a-e8b62c7811e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agentic_rag_v1('how do I join the course?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00027513-e48b-4b6d-971c-93c8306fe5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agentic_rag_v1('how patch KDE under FreeBSD?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e137ff66-06c0-41e6-b32f-b8d2225f738b",
   "metadata": {},
   "source": [
    "# Part 2: Agentic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c13efa-968b-4639-b4ca-c6039de93a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can let our \"agent\" formulate one or more search queries - and do it for a few iterations until we found an answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1282bf24-c4c0-48fe-b057-a52f6f19d02a",
   "metadata": {},
   "source": [
    "## Update Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "374280d1-4f58-4b30-9897-e879d9f49109",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "\n",
    "The CONTEXT is build with the documents from our FAQ database.\n",
    "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
    "from FAQ to and add them to the context.\n",
    "PREVIOUS_ACTIONS contains the actions you already performed.\n",
    "\n",
    "At the beginning the CONTEXT is empty.\n",
    "\n",
    "You can perform the following actions:\n",
    "\n",
    "- Search in the FAQ database to get more data for the CONTEXT\n",
    "- Answer the question using the CONTEXT\n",
    "- Answer the question using your own knowledge\n",
    "\n",
    "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
    "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
    "\n",
    "Don't use search queries used at the previous iterations.\n",
    "\n",
    "Don't repeat previously performed actions.\n",
    "\n",
    "Don't perform more than {max_iterations} iterations for a given student question.\n",
    "The current iteration number: {iteration_number}. If we exceed the allowed number \n",
    "of iterations, give the best possible answer with the provided information.\n",
    "\n",
    "Output templates:\n",
    "\n",
    "If you want to perform search, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\",\n",
    "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER_CONTEXT\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{previous_actions}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5e69ef-f4c4-4524-b08e-ee9258ded7e7",
   "metadata": {},
   "source": [
    "## First iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12801c77-0656-4c41-a47d-e8f95e8615d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the first iteration, we have this\n",
    "question = \"how do I join the course?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=3,\n",
    "    iteration_number=1\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f6e0a-a473-4986-b587-5a95365aae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(json.dumps(answer, indent=2))\n",
    "\n",
    "# {\n",
    "#   \"action\": \"SEARCH\",\n",
    "#   \"reasoning\": \"I need to find specific information on how to join the course, as this information is not present in the current CONTEXT.\",\n",
    "#   \"keywords\": [\n",
    "#     \"how to join the course\",\n",
    "#     \"course enrollment process\",\n",
    "#     \"register for the course\"\n",
    "#   ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dcb187-dd8b-447e-815f-f9d6ee7a334b",
   "metadata": {},
   "source": [
    "## Save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a51e0-bb12-410e-a845-5cf6d949414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to save the actions\n",
    "previous_actions.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f94553-20b0-4d75-bd0d-8c71af32ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the search queries\n",
    "keywords = answer['keywords']\n",
    "search_queries.extend(keywords)\n",
    "\n",
    "# And the search results\n",
    "for k in keywords:\n",
    "    res = search(k)\n",
    "    search_results.extend(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20156e1f-4603-4e00-bfcd-1b3e9dc2b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the search results will be duplicates, so we need to remove them\n",
    "def dedup(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result\n",
    "\n",
    "search_results = dedup(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b70074-2dc7-4e92-9c4e-91d67ccf5853",
   "metadata": {},
   "source": [
    "## Another iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc71a17-0856-4bf0-93ef-9d76a66ea915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's make another iteration - use the same code as previously, \n",
    "# but remove variable initialization and increase the iteration number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e26bf-0c5c-4a50-9270-c6f6d71a364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"how do I join the course?\"\n",
    "\n",
    "# search_queries = []\n",
    "# search_results = []\n",
    "# previous_actions = []\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=3,\n",
    "    iteration_number=2\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)\n",
    "print(json.dumps(answer, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6acf70-a2f7-4ea1-b91d-51f9d1a2840f",
   "metadata": {},
   "source": [
    "## Put everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78f91eaa-ebcd-441b-b429-7465c7365c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_search(question):\n",
    "    search_queries = []\n",
    "    search_results = []\n",
    "    previous_actions = []\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        print(f'ITERATION #{iteration}...')\n",
    "    \n",
    "        context = build_context(search_results)\n",
    "        prompt = prompt_template.format(\n",
    "            question=question,\n",
    "            context=context,\n",
    "            search_queries=\"\\n\".join(search_queries),\n",
    "            previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "            max_iterations=3,\n",
    "            iteration_number=iteration\n",
    "        )\n",
    "    \n",
    "        print(prompt)\n",
    "    \n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(json.dumps(answer, indent=2))\n",
    "\n",
    "        previous_actions.append(answer)\n",
    "    \n",
    "        action = answer['action']\n",
    "        if action != 'SEARCH':\n",
    "            break\n",
    "    \n",
    "        keywords = answer['keywords']\n",
    "        search_queries = list(set(search_queries) | set(keywords))\n",
    "\n",
    "        for k in keywords:\n",
    "            res = search(k)\n",
    "            search_results.extend(res)\n",
    "    \n",
    "        search_results = dedup(search_results)\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        if iteration >= 4:\n",
    "            break\n",
    "    \n",
    "        print()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5865af-5c1f-4c4f-83d3-08e9c2ffec04",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af7f83-edc2-4054-a8f5-8615a8446ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentic_search('how do I prepare for the course?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e566bb3-bce1-4ca8-81f8-a6bc550b3290",
   "metadata": {},
   "source": [
    "# Part 3: Function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f1513-abef-4a0c-9ae3-35870e801a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We put all this logic inside our prompt.\n",
    "# But OpenAI and other providers provide a convenient API for adding extra functionality like search.\n",
    "# https://platform.openai.com/docs/guides/function-calling\n",
    "# It's called \"function calling\" - you define functions that the model can call, and if it decides to make a call, it returns structured output for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c3872e-f0ca-4cdc-bfa8-6bba1477da4a",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a0843-af35-4004-80b8-1674b14cbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, let's take our search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1e1f58d-93f4-43e7-a3ee-fb3c2b630f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4655f16b-0fc5-45c4-8d06-4853c79e20a0",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c7def1a-55fe-406e-9485-843873a9da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We describe it like that for OpenAi\n",
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48075a5c-7d32-486a-bf02-9855b1a8a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have:\n",
    "\n",
    "# name: search\n",
    "# description: when to use it\n",
    "# parameters: all the arguments that the function can take and their description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5816cb91-c0ec-4d32-90d6-bae1abe40987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to use function calling, we'll use a newer API - the \"responses\" API (not \"chat completions\" as previously) for OpenAI\n",
    "question = \"How do I do well in module 1?\"\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\"\"\".strip()\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e1d728-0058-46c5-8f9e-3cc5bd4d1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ResponseFunctionToolCall(arguments='{\"query\":\"How to do well in module 1\"}',\n",
    "#                           call_id='call_AwYwOak5Ljeidh4HbE3RxMZJ', \n",
    "#                           name='search', \n",
    "#                           type='function_call', \n",
    "#                           id='fc_6848604db67881a298ec38121c1555ef0dee5fa0cdb59912', \n",
    "#                           status='completed')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95a4702-5d13-4075-94db-c02304792a9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46a6ac17-b352-4852-bfa0-ddf0f024400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We describe it like that for Mistral\n",
    "# search_tool_mistral = {\n",
    "#     \"type\": \"function\",\n",
    "#     \"function\": {\n",
    "#         \"name\": \"search\",\n",
    "#         \"description\": \"Search the FAQ database\",\n",
    "#         \"parameters\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"query\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"query\"],\n",
    "#             \"additionalProperties\": False\n",
    "#         }\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca03a65-b030-4964-8a0f-571b759f15cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In order to use function calling, we'll use a newer API - the \"responses\" API (not \"chat completions\" as previously) for Mistral\n",
    "# question = \"How do I do well in module 1?\"\n",
    "\n",
    "# developer_prompt = \"\"\"\n",
    "# You're a course teaching assistant. \n",
    "# You're given a question from a course student and your task is to answer it.\n",
    "# \"\"\".strip()\n",
    "\n",
    "# tools = [search_tool]\n",
    "\n",
    "# chat_messages = [\n",
    "#     {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "#     {\"role\": \"user\", \"content\": question}\n",
    "# ]\n",
    "\n",
    "# response = client.chat.complete(\n",
    "#     model = model,\n",
    "#     messages = chat_messages,\n",
    "#     tools = search_tool_mistral,\n",
    "#     tool_choice = \"any\",\n",
    "#     parallel_tool_calls = False,\n",
    "# )\n",
    "# response.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabce6cf-6522-4fc2-9294-5e651e5f1c2b",
   "metadata": {},
   "source": [
    "## Call to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a6063-8c52-45b2-8aed-57311d50f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls = response.output\n",
    "call = calls[0]\n",
    "call\n",
    "\n",
    "call_id = call.call_id\n",
    "call_id\n",
    "\n",
    "f_name = call.name\n",
    "f_name\n",
    "\n",
    "arguments = json.loads(call.arguments)\n",
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a2d97-2856-4e67-a5ec-d6ac530cb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using f_name we can find the function we need\n",
    "f = globals()[f_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148dab83-d4b5-4370-984c-967d6f20a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And invoke it with the arguments\n",
    "results = f(**arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0e229-9889-44db-9bec-1a55e4bc3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's save the results as json\n",
    "search_results = json.dumps(results, indent=2)\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b124a7e-554b-44ea-80b2-fe688d9f7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And save both the response and the result of the function call\n",
    "chat_messages.append(call)\n",
    "\n",
    "chat_messages.append({\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": call.call_id,\n",
    "    \"output\": search_results,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e88e2-756e-4225-bccd-445a6bcb916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now chat_messages contains both the call description (so it keeps track of history) and the results\n",
    "# Let's make another call to the model\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a146284d-0396-40b4-aac9-99e3a5696f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time it should be the response (but also can be another call)\n",
    "r = response.output[0]\n",
    "print(r.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43731853-1b33-4bc5-b37b-cfa435718969",
   "metadata": {},
   "source": [
    "## Multiple calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477328f6-0f48-4f32-b763-a637edcc7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want to make multiple calls? Change the developer prompt a little\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "If you look up something in FAQ, convert the student question into multiple queries.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a20492-bd2d-4771-83fa-f70045175490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a function do_call\n",
    "\n",
    "def do_call(tool_call_response):\n",
    "    function_name = tool_call_response.name\n",
    "    arguments = json.loads(tool_call_response.arguments)\n",
    "\n",
    "    f = globals()[function_name]\n",
    "    result = f(**arguments)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"call_id\": tool_call_response.call_id,\n",
    "        \"output\": json.dumps(result, indent=2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e02a705-248b-483f-8089-70ccd27bf1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now iterate over responses\n",
    "\n",
    "for entry in response.output:\n",
    "    chat_messages.append(entry)\n",
    "    print(entry.type)\n",
    "\n",
    "    if entry.type == 'function_call':      \n",
    "        result = do_call(entry)\n",
    "        chat_messages.append(result)\n",
    "    elif entry.type == 'message':\n",
    "        print(entry.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050c4a9-1af1-4265-a561-0fc727e9933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First call will probably be function call, so let's do another one\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "for entry in response.output:\n",
    "    chat_messages.append(entry)\n",
    "    print(entry.type)\n",
    "    print()\n",
    "\n",
    "    if entry.type == 'function_call':      \n",
    "        result = do_call(entry)\n",
    "        chat_messages.append(result)\n",
    "    elif entry.type == 'message':\n",
    "        print(entry.content[0].text) \n",
    "# This one is a text response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da33c80a-d6e0-4e60-b04a-3e9c198b9dc7",
   "metadata": {},
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9b2250-f75f-4026-b3eb-afa6a5b03af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But what if it's not?\n",
    "\n",
    "# Let's make two loops:\n",
    "# First is the main Q&A loop - ask question, get back the answer\n",
    "# Second is the request loop - send requests until there's a message reply from the API\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "When using FAQ, perform deep topic exploration: make one request to FAQ,\n",
    "and then based on the results, make more requests.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee5515-7042-470b-8511-8ee8a9f34f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True: # main Q&A loop\n",
    "    question = input() # How do I do my best for module 1?\n",
    "    if question == 'stop':\n",
    "        break\n",
    "\n",
    "    message = {\"role\": \"user\", \"content\": question}\n",
    "    chat_messages.append(message)\n",
    "\n",
    "    while True: # request-response loop - query API till get a message\n",
    "        response = client.responses.create(\n",
    "            model='gpt-4o-mini',\n",
    "            input=chat_messages,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        has_messages = False\n",
    "        \n",
    "        for entry in response.output:\n",
    "            chat_messages.append(entry)\n",
    "        \n",
    "            if entry.type == 'function_call':      \n",
    "                print('function_call:', entry)\n",
    "                print()\n",
    "                result = do_call(entry)\n",
    "                chat_messages.append(result)\n",
    "            elif entry.type == 'message':\n",
    "                print(entry.content[0].text)\n",
    "                print()\n",
    "                has_messages = True\n",
    "\n",
    "        if has_messages:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf7daf-4991-4828-a632-8f2849bb2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make it a bit nicer using HTML:\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import markdown # pip install markdown    \n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "]\n",
    "\n",
    "# Chat loop\n",
    "while True:\n",
    "    \n",
    "    if question.strip().lower() == 'stop':\n",
    "        print(\"Chat ended.\")\n",
    "        break\n",
    "    print()\n",
    "\n",
    "    message = {\"role\": \"user\", \"content\": question}\n",
    "    chat_messages.append(message)\n",
    "\n",
    "    while True:  # inner request loop\n",
    "        response = client.responses.create(\n",
    "            model='gpt-4o-mini',\n",
    "            input=chat_messages,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        has_messages = False\n",
    "\n",
    "        for entry in response.output:\n",
    "            chat_messages.append(entry)\n",
    "\n",
    "            if entry.type == \"function_call\":\n",
    "                result = do_call(entry)\n",
    "                chat_messages.append(result)\n",
    "                display_function_call(entry, result)\n",
    "\n",
    "            elif entry.type == \"message\":\n",
    "                display_response(entry)\n",
    "                has_messages = True\n",
    "\n",
    "        if has_messages:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8781f730-4919-4772-ad4e-1a87d49f37fd",
   "metadata": {},
   "source": [
    "## Using multiple tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf31dc-d7e3-4e98-afe8-1eeb236d43db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we also want to use this chat app to add new entries to the FAQ? We'll need another function for it:\n",
    "\n",
    "def add_entry(question, answer):\n",
    "    doc = {\n",
    "        'question': question,\n",
    "        'text': answer,\n",
    "        'section': 'user added',\n",
    "        'course': 'data-engineering-zoomcamp'\n",
    "    }\n",
    "    index.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f6c31-4833-46e4-b54c-042724ab41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description\n",
    "add_entry_description = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"add_entry\",\n",
    "    \"description\": \"Add an entry to the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question to be added to the FAQ database\",\n",
    "            },\n",
    "            \"answer\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The answer to the question\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"question\", \"answer\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b78678-1b21-43bb-a587-41f82be955d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use chat_assistant\n",
    "\n",
    "import chat_assistant\n",
    "\n",
    "tools = chat_assistant.Tools()\n",
    "tools.add_tool(search, search_tool)\n",
    "\n",
    "tools.get_tools()\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ba5cb-338a-4715-92cf-18a5f8268bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And run it\n",
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c2a8e7-7b3d-4806-966d-96fe593f09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's add the new tool\n",
    "tools.add_tool(add_entry, add_entry_description)\n",
    "tools.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99cb585-7735-4b34-912f-404a6d19f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And talk with the assistant:\n",
    "\n",
    "# How do I do well for module 1?\n",
    "# Add this back to FAQ\n",
    "# And check that it's in the index:\n",
    "\n",
    "index.docs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8581dbb0-31e3-4555-92c9-39e400cb8a48",
   "metadata": {},
   "source": [
    "# Part 4: Using PydanticAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e4ad1-275d-41bd-b7a1-e6ab0884109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pydantic-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307aa48-ccb0-4709-8500-2a5b3db43ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent, RunContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65da65ab-8793-4332-907f-16269b8afb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an agent\n",
    "chat_agent = Agent(  \n",
    "    'openai:gpt-4o-mini',\n",
    "    system_prompt=developer_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2b027-c093-47af-915e-8a7494971664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use it to automate tool description:\n",
    "from typing import Dict\n",
    "\n",
    "@chat_agent.tool\n",
    "def search_tool(ctx: RunContext, query: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Search the FAQ for relevant entries matching the query.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        The search query string provided by the user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of search results (up to 5), each containing relevance information \n",
    "        and associated output IDs.\n",
    "    \"\"\"\n",
    "    print(f\"search('{query}')\")\n",
    "    return search(query)\n",
    "\n",
    "\n",
    "@chat_agent.tool\n",
    "def add_entry_tool(ctx: RunContext, question: str, answer: str) -> None:\n",
    "    \"\"\"\n",
    "    Add a new question-answer entry to FAQ.\n",
    "\n",
    "    This function creates a document with the given question and answer, \n",
    "    tagging it as user-added content.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    question : str\n",
    "        The question text to be added to the index.\n",
    "\n",
    "    answer : str\n",
    "        The answer or explanation corresponding to the question.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    return add_entry(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e1dc2-4389-4a6f-b420-6932e79dab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It reads the functions' docstrings to automatically create function definition, so we don't need to worry about it\n",
    "# Let's use it:\n",
    "\n",
    "user_prompt = \"I just discovered the course. Can I join now?\"\n",
    "agent_run = await chat_agent.run(user_prompt)\n",
    "print(agent_run.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dcd448-01bf-4b21-ba6a-6b8918b32f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
